{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Round2 Workflow using Argus - Leo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne2a5BErfjB1",
        "outputId": "cf574565-89d2-437d-82d7-1129e48072f5"
      },
      "source": [
        "!pip install segmentation-models-pytorch==0.1.2         # easy to use some famous model architecture. visit https://github.com/qubvel/segmentation_models.pytorch/\n",
        "!pip install albumentations                             # easy image manipulation for data augmentation\n",
        "!pip install -U git+https://github.com/lRomul/argus.git  # easy training model\n",
        "!pip install pytorch-toolbelt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation-models-pytorch==0.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/36/37b6b0e54a98ff15eb36ce36c9181fdb627b3e789e23fc764f9e5f01dc68/segmentation_models_pytorch-0.1.2-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hCollecting pretrainedmodels==0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hCollecting timm==0.1.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/26/ba294669cc5cc4d09efd1964c8df752dc0955ac26f86bdeec582aed77d1d/timm-0.1.20-py3-none-any.whl (161kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 35.4MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from segmentation-models-pytorch==0.1.2) (0.8.1+cu101)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (1.7.0+cu101)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (4.41.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation-models-pytorch==0.1.2) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation-models-pytorch==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.1.2) (1.15.0)\n",
            "Building wheels for collected packages: pretrainedmodels, efficientnet-pytorch\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60963 sha256=bf1203ec9a753ee6dd9842ddf300542a57783840bb8f180efedfd79869141902\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12421 sha256=98735ca3af64cf7b1f4d5cba7afb2b5e16f94873db4d6c2ea505bf21acd79e05\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built pretrainedmodels efficientnet-pytorch\n",
            "Installing collected packages: munch, pretrainedmodels, timm, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.2 timm-0.1.20\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (0.1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.19.5)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 19.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=4616bb307cea18b53c5194bdb197f87805394df14ce636d9b8c04aebd4c015f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.6\n",
            "Collecting git+https://github.com/lRomul/argus.git\n",
            "  Cloning https://github.com/lRomul/argus.git to /tmp/pip-req-build-ajslmlbl\n",
            "  Running command git clone -q https://github.com/lRomul/argus.git /tmp/pip-req-build-ajslmlbl\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-argus==0.2.0) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->pytorch-argus==0.2.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->pytorch-argus==0.2.0) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->pytorch-argus==0.2.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->pytorch-argus==0.2.0) (3.7.4.3)\n",
            "Building wheels for collected packages: pytorch-argus\n",
            "  Building wheel for pytorch-argus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-argus: filename=pytorch_argus-0.2.0-cp36-none-any.whl size=33101 sha256=15c9f9a05711cd510cf1183fb870bdb37e67d94553260aaba35c2633e472c458\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z9lkewrw/wheels/63/17/a1/1b166de770d7ca23feb6b3f9cb0cb65a5ea7c540bc56ff04ca\n",
            "Successfully built pytorch-argus\n",
            "Installing collected packages: pytorch-argus\n",
            "Successfully installed pytorch-argus-0.2.0\n",
            "Collecting pytorch-toolbelt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/ec/62f4c097551fadcf9fdf088a9cc10aee4e7447c339f76eee842b8fbe69be/pytorch_toolbelt-0.4.1.tar.gz (109kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-toolbelt) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytorch-toolbelt) (0.8.1+cu101)\n",
            "Requirement already satisfied: opencv-python>=4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-toolbelt) (4.1.2.30)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch-toolbelt) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch-toolbelt) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch-toolbelt) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch-toolbelt) (0.8)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.5->pytorch-toolbelt) (7.0.0)\n",
            "Building wheels for collected packages: pytorch-toolbelt\n",
            "  Building wheel for pytorch-toolbelt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-toolbelt: filename=pytorch_toolbelt-0.4.1-cp36-none-any.whl size=145548 sha256=60de81a17084b3a2cfcc2a1252257eaa4de187e19d8825b8edd381cbeb50fe5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/3f/f2/d205fca8c5623f99ada05bdd1e0b2b91c1b0b62eabda7e9071\n",
            "Successfully built pytorch-toolbelt\n",
            "Installing collected packages: pytorch-toolbelt\n",
            "Successfully installed pytorch-toolbelt-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVFzsD64f9-Y"
      },
      "source": [
        "from copy import copy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "torch.backends.cudnn.benchmark = True\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "\n",
        "from pytorch_toolbelt.losses import LovaszLoss\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import argus\n",
        "from argus.callbacks import MonitorCheckpoint, EarlyStopping, LoggingToFile, ReduceLROnPlateau, LoggingToCSV\n",
        "from argus.metrics import Metric\n",
        "import albumentations as A\n",
        "\n",
        "\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t5LMzlYiJ2K"
      },
      "source": [
        "def _prf_divide(numerator, denominator, ):\n",
        "    \"\"\"Performs division and handles divide-by-zero.\n",
        "    On zero-division, sets the corresponding result elements equal to\n",
        "    0 or 1 (according to ``zero_division``). \n",
        "    \"\"\"\n",
        "    mask = denominator == 0.0\n",
        "    denominator = denominator.copy()\n",
        "    denominator[mask] = 1  # avoid infs/nans\n",
        "    result = numerator / denominator\n",
        "\n",
        "    return result\n",
        "\n",
        "def compute_scores(y_true, y_pred, class_weights=[1, 1, 1, 1, 20, 20]):\n",
        "    \"\"\"\n",
        "    Computes the weighted & unweighted f1_score and accuracy\n",
        "    Using the standard F1-Score and class-wise accuracy computations were quite \n",
        "    slow as we were doing a lot of redundant work across all score computations,\n",
        "    hence we have implemented this from the base principles.\n",
        "    Please refer to the inline comments.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initial Housekeeping Taks1\n",
        "    y_true = np.array(y_true).flatten()\n",
        "    y_pred = np.array(y_pred).flatten()\n",
        "    class_weights = np.array(class_weights)\n",
        "    # print(np.max(y_true))\n",
        "    # print(np.max(y_pred))\n",
        "    # print(np.min(y_true))\n",
        "    # print(np.min(y_pred))\n",
        "    # Computing Multilabel Confusion Matrix\n",
        "    #print(\"--------- Computing MCM... \")\n",
        "    begin_time = time.time()\n",
        "    MCM = multilabel_confusion_matrix(y_true, y_pred,labels=[1,2,3,4,5,6])\n",
        "    #print(\"MCM computation time  : \", time.time() - begin_time)\n",
        "    \n",
        "    \"\"\"\n",
        "    Gather True Positives, True Negatives, False Positives, False Negatives\n",
        "    \"\"\"\n",
        "    tp_sum = MCM[:, 1, 1]\n",
        "    tn_sum = MCM[:, 0, 0]\n",
        "    fn_sum = MCM[:, 1, 0]\n",
        "    fp_sum = MCM[:, 0, 1]\n",
        "    \n",
        "    #print(\"--------- Computing per class instances... \")\n",
        "    per_class_instances = np.bincount(y_true) # Helps keep a track of total number of instances per class\n",
        "    per_class_instances = per_class_instances[1:] # as the class names in the dataset are NOT zero-indexed\n",
        "    \n",
        "    assert class_weights.shape == per_class_instances.shape\n",
        "    \n",
        "    #print(\"--------- Computing precision... \")\n",
        "    # precision : tp / (tp + fp)\n",
        "    precision = _prf_divide(\n",
        "                    tp_sum,\n",
        "                    (tp_sum + fp_sum)\n",
        "                )\n",
        "    #print(\"--------- Computing recall... \")                        \n",
        "    # recall : tp / (tp + fn)\n",
        "    recall = _prf_divide(\n",
        "                    tp_sum,\n",
        "                    (tp_sum + fn_sum)\n",
        "                )\n",
        "\n",
        "    #print(\"--------- Computing F1 score... \")\n",
        "    # f1 : 2 * (recall * precision) / (recall + precision)\n",
        "    f1_score = _prf_divide(\n",
        "                    2 * precision * recall,\n",
        "                    precision + recall\n",
        "                )\n",
        "    #print(\"--------- Computing Accuracy... \")\n",
        "    # accuracy = tp_sum / instances_per_class\n",
        "    # NOTE: we are computing the accuracy independently for all the class specific subgroups\n",
        "    # accuracy = _prf_divide(\n",
        "    #                 tp_sum,\n",
        "    #                 per_class_instances\n",
        "    #             )\n",
        "    # print(class_weights)\n",
        "    # print(f1_score)\n",
        "    f1_score_weighted = np.dot(class_weights, f1_score) / np.sum(class_weights)\n",
        "    f1_score_unweighted = f1_score.mean()\n",
        "\n",
        "    # accuracy_weighted = np.dot(class_weights, accuracy) / np.sum(class_weights)\n",
        "    # accuracy_unweighted = accuracy.mean()\n",
        "\n",
        "    return f1_score_weighted#, accuracy_weighted, f1_score_unweighted, accuracy_unweighted\n",
        "\n",
        "class CategoricalAccuracy(Metric):\n",
        "    \"\"\"Calculates the accuracy for multiclass classification.\"\"\"\n",
        "\n",
        "    name = 'f1facies'\n",
        "    better = 'max'\n",
        "\n",
        "    def __init__(self):\n",
        "        self.score = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.score = 0\n",
        "\n",
        "    def update(self, step_output: dict):\n",
        "        # preds = step_output['prediction'].cpu().numpy()\n",
        "        preds = step_output['prediction'].max(1)[1].cpu().numpy()[:, :, :]+1\n",
        "        # print(preds[0,:,:])\n",
        "        # print(preds.shape)\n",
        "        trgs = step_output['target'].cpu().numpy()+1\n",
        "        # print(trgs[0,:,:])\n",
        "        # print(trgs.shape)\n",
        "        self.score =  compute_scores(trgs, preds)\n",
        "\n",
        "    def compute(self):\n",
        "\n",
        "        return self.score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc2IVoT-ismh"
      },
      "source": [
        "class LovaszBCELoss(torch.nn.Module):\n",
        "    def __init__(self, lovasz_weight=0.75, ce_weight=0.25):\n",
        "        super().__init__()\n",
        "        self.lovasz_weight = lovasz_weight\n",
        "        self.ce_weight = ce_weight\n",
        "        self.ce = torch.nn.CrossEntropyLoss()\n",
        "        self.lovasz = LovaszLoss()\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        if self.lovasz_weight > 0:\n",
        "            lovasz = self.lovasz(torch.softmax(output, dim=1), target) * self.lovasz_weight\n",
        "        else:\n",
        "            lovasz = 0\n",
        "\n",
        "        if self.ce_weight > 0:\n",
        "            ce = self.ce(output, target.long()) * self.ce_weight\n",
        "        else:\n",
        "            ce = 0\n",
        "\n",
        "        return lovasz + ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1veGS22ylI7j",
        "outputId": "01962f36-1416-43a9-dd14-cbc06e3d0868"
      },
      "source": [
        "#data that processed then rescaled to 0-1 (check main explainer)\n",
        "!gdown \"https://drive.google.com/uc?id=19Ku7UMjvWhwJ1_7Ii7_AaF5Eoyl-24ul\"\n",
        "!gdown \"https://drive.google.com/uc?id=1HL0bwFIhUx8A25644JbmpozNQ0jwmWCT\"\n",
        "!gdown \"https://drive.google.com/uc?id=1o8lvBdvsh3-sI3dsE-p6H9SNzFbY_ksC\"\n",
        "!gdown \"https://drive.google.com/uc?id=1b5MoCr0VoRG_6R_h1JO7dx6mZgO6Zz8J\"\n",
        "!gdown \"https://drive.google.com/uc?id=1hYCxIJIgbow6IYpIxwAJXdfiloC8PFYq\"\n",
        "!gdown \"https://drive.google.com/uc?id=1JZ5LZz_f2Vfg9BxuGGBY9LliJQAAHi_H\"\n",
        "!gdown \"https://drive.google.com/uc?id=1--tADAa10l2M1iaSEslGXK-RaBv8UbMf\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19Ku7UMjvWhwJ1_7Ii7_AaF5Eoyl-24ul\n",
            "To: /content/data_train_procsed.npz\n",
            "1.62GB [00:15, 105MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HL0bwFIhUx8A25644JbmpozNQ0jwmWCT\n",
            "To: /content/data_174_251_trainolah.npz\n",
            "5.91MB [00:00, 18.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o8lvBdvsh3-sI3dsE-p6H9SNzFbY_ksC\n",
            "To: /content/label_174_251_train.npz\n",
            "100% 28.7k/28.7k [00:00<00:00, 4.21MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1b5MoCr0VoRG_6R_h1JO7dx6mZgO6Zz8J\n",
            "To: /content/data_test2_75_174_olahnorm.npz\n",
            "5.90MB [00:00, 52.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hYCxIJIgbow6IYpIxwAJXdfiloC8PFYq\n",
            "To: /content/label75_174_test_round2.npz\n",
            "100% 27.1k/27.1k [00:00<00:00, 3.99MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JZ5LZz_f2Vfg9BxuGGBY9LliJQAAHi_H\n",
            "To: /content/data_train_processed.npz\n",
            "1.73GB [00:35, 48.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--tADAa10l2M1iaSEslGXK-RaBv8UbMf\n",
            "To: /content/labels_train.npz\n",
            "7.16MB [00:00, 112MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWMqBXZWgIg7"
      },
      "source": [
        "train_dat = np.load('data_train_procsed.npz', allow_pickle=True, mmap_mode='r')['data'].astype('float32')\n",
        "train_labels = np.load('labels_train.npz', allow_pickle=True, mmap_mode='r')['labels']\n",
        "\n",
        "#confidence pseudolabels that we got from round 1\n",
        "ex_dat = np.load('data_174_251_trainolah.npz', allow_pickle=True, mmap_mode='r')['data'].astype('float32')\n",
        "ex_labels = np.load('label_174_251_train.npz', allow_pickle=True, mmap_mode='r')['label']\n",
        "\n",
        "#appending the data\n",
        "train_dat = np.append(train_dat,ex_dat[:,841-782:,:],axis=2)\n",
        "train_labels = np.append(train_labels,ex_labels[:,841-782:,:],axis=2)\n",
        "\n",
        "#confidence pseudolabels that got from error map round 2\n",
        "test_dat = np.load('data_test2_75_174_olahnorm.npz', allow_pickle=True, mmap_mode='r')['data']\n",
        "test_labels = np.load('label75_174_test_round2.npz', allow_pickle=True, mmap_mode='r')['label']\n",
        "\n",
        "train_dat=train_dat.transpose(1, 0, 2)\n",
        "train_labels=train_labels.transpose(1, 0, 2)\n",
        "test_dat=test_dat.transpose(2, 0, 1)\n",
        "test_labels=test_labels.transpose(2, 0, 1)\n",
        "train_labels -= 1\n",
        "test_labels -= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jMCYQ7Yox0D"
      },
      "source": [
        "#setting dataset\n",
        "class DataGeneratorTrain(Dataset):\n",
        "    def __init__(self, x_set, y_set):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.xaxis = self.x.shape[0]\n",
        "        self.yaxis = self.x.shape[2]\n",
        "        self.aug = A.Compose([\n",
        "            #A.RandomSizedCrop(p=1.0, min_max_height=(1006, 1006), height=1006, width=256, w2h_ratio=1.0, interpolation=0),\n",
        "            A.RandomCrop(1006, 130, p=1.0),\n",
        "            A.ShiftScaleRotate(p=0.5, shift_limit=(0.0, 0.0), scale_limit=(0.01, 0.25), rotate_limit=(-15, 15), interpolation=0, border_mode=1),\n",
        "            A.Resize(p=1, height=1000, width=128, interpolation=0)\n",
        "            \n",
        "        ]) \n",
        "        self.aug2 = A.Compose([\n",
        "            #A.RandomSizedCrop(p=1.0, min_max_height=(1006, 1006), height=1006, width=256, w2h_ratio=1.0, interpolation=0),\n",
        "            A.RandomCrop(1006, 130, p=1.0),\n",
        "            #A.Blur(p=1.0, blur_limit=(3, 3))\n",
        "            # A.flip()\n",
        "            A.ShiftScaleRotate(p=0.5, shift_limit=(0.0, 0.0), scale_limit=(0.01, 0.25), rotate_limit=(-3, 3), interpolation=0, border_mode=1),\n",
        "            A.Resize(p=1, height=1000, width=128, interpolation=0)\n",
        "            \n",
        "        ])  \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.xaxis+self.yaxis\n",
        "    \n",
        "    def __getitem__(self, index):   \n",
        "        if index < self.xaxis:\n",
        "            batch_x = self.x[index,:,:]\n",
        "            batch_y = self.y[index]\n",
        "\n",
        "        else:\n",
        "            batch_x = self.x[:,:,index-len(self.x)].T\n",
        "            batch_y = self.y[:,:,index-len(self.x)].T\n",
        "\n",
        "        augmented = self.aug(image=batch_x, mask=batch_y)\n",
        "\n",
        "        image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        return image[None,:,:], mask\n",
        "\n",
        "class DataGeneratorTest(Dataset):\n",
        "    def __init__(self, x_set, y_set):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.aug = A.Compose([\n",
        "            A.Resize(p=1, height=1000, width=128, interpolation=0)\n",
        "        ])        \n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.x.shape[2]/130)*2)#len(self.x)*\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        idx=int(np.floor(index/np.ceil(self.x.shape[2]/130)))\n",
        "        idy=int(index%np.ceil(self.x.shape[2]/130))\n",
        "        \n",
        "        if idy==int(self.x.shape[2]/130):\n",
        "            batch_x = self.x[idx,:,self.x.shape[2]-130:]\n",
        "            batch_y = self.y[idx,:,self.x.shape[2]-130:]\n",
        "        else:\n",
        "            batch_x = self.x[idx,:,idy*130:idy*130+130]\n",
        "            batch_y = self.y[idx,:,idy*130:idy*130+130]\n",
        "\n",
        "        augmented = self.aug(image=batch_x, mask=batch_y)\n",
        "        image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        return image[None,:,:], mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k5HZR84pwma"
      },
      "source": [
        "#setting the architecture, losses, optimizer, etc.\n",
        "class SeismicFaciesModel(argus.Model):\n",
        "    nn_module = smp.PAN\n",
        "    optimizer = optim.Adam\n",
        "    loss = LovaszBCELoss\n",
        "\n",
        "params = {\n",
        "    'nn_module': {\n",
        "        'encoder_name': 'efficientnet-b3',\n",
        "        'classes': 6,\n",
        "        'in_channels': 1,\n",
        "        'encoder_weights': None,\n",
        "        'activation': None\n",
        "    },\n",
        "    'loss': {\n",
        "        'lovasz_weight': 0.75,\n",
        "        'ce_weight': 0.25,\n",
        "    },\n",
        "    'optimizer': {'lr': 0.0009},\n",
        "    'device': 'cuda'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n74meH3p3Qy"
      },
      "source": [
        "def get_data_loaders(batch_size):\n",
        "    train_dataset = DataGeneratorTrain(x_set=train_dat,y_set=train_labels) \n",
        "    test_dataset = DataGeneratorTest(x_set=test_dat,y_set=test_labels) \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=14, shuffle=True) \n",
        "    return train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfms3a1GqAPa"
      },
      "source": [
        "bsize=6\n",
        "train_loader, val_loader= get_data_loaders(batch_size=bsize)\n",
        "model = SeismicFaciesModel(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUbPNaRZqXYx"
      },
      "source": [
        "callbacks = [\n",
        "    MonitorCheckpoint(dir_path=f'panet_r1', monitor='val_f1facies', max_saves=25),\n",
        "    ReduceLROnPlateau(monitor='val_loss', patience=30, factor=0.64, min_lr=1e-8),\n",
        "    EarlyStopping(monitor='val_loss', patience=50),\n",
        "    LoggingToFile(f'panet_r1.log'),\n",
        "    LoggingToCSV(f'panet_r1.csv')\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jZ0xsYJqewK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21bad249-e3b2-4dea-b072-8ba7d146a649"
      },
      "source": [
        "#this will take forefer..\n",
        "model.fit(train_loader,\n",
        "      val_loader=val_loader,\n",
        "      num_epochs=200,\n",
        "      metrics=['f1facies'],\n",
        "      callbacks=callbacks,\n",
        "      metrics_on_train=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-02-10 07:19:16,138][INFO]: val - epoch: -1, val_loss: 1.072965, val_f1facies: 0.01064363\n",
            "[2021-02-10 07:20:37,849][INFO]: train - epoch: 0, lr: 0.0009, train_loss: 0.8203805\n",
            "[2021-02-10 07:20:38,382][INFO]: val - epoch: 0, val_loss: 0.9873087, val_f1facies: 0.01345567\n",
            "[2021-02-10 07:20:38,490][INFO]: Model saved to 'panet_r1/model-000-0.013456.pth'\n",
            "[2021-02-10 07:21:59,209][INFO]: train - epoch: 1, lr: 0.0009, train_loss: 0.7320742\n",
            "[2021-02-10 07:21:59,745][INFO]: val - epoch: 1, val_loss: 0.9373235, val_f1facies: 0.05616276\n",
            "[2021-02-10 07:21:59,868][INFO]: Model saved to 'panet_r1/model-001-0.056163.pth'\n",
            "[2021-02-10 07:23:21,143][INFO]: train - epoch: 2, lr: 0.0009, train_loss: 0.7168491\n",
            "[2021-02-10 07:23:21,692][INFO]: val - epoch: 2, val_loss: 0.7888632, val_f1facies: 0.7070905\n",
            "[2021-02-10 07:23:21,804][INFO]: Model saved to 'panet_r1/model-002-0.707091.pth'\n",
            "[2021-02-10 07:24:44,168][INFO]: train - epoch: 3, lr: 0.0009, train_loss: 0.7072418\n",
            "[2021-02-10 07:24:44,703][INFO]: val - epoch: 3, val_loss: 0.8112245, val_f1facies: 0.6599934\n",
            "[2021-02-10 07:26:07,206][INFO]: train - epoch: 4, lr: 0.0009, train_loss: 0.7052375\n",
            "[2021-02-10 07:26:07,736][INFO]: val - epoch: 4, val_loss: 0.7937496, val_f1facies: 0.6565722\n",
            "[2021-02-10 07:27:30,195][INFO]: train - epoch: 5, lr: 0.0009, train_loss: 0.699342\n",
            "[2021-02-10 07:27:30,734][INFO]: val - epoch: 5, val_loss: 0.7744428, val_f1facies: 0.641793\n",
            "[2021-02-10 07:28:53,166][INFO]: train - epoch: 6, lr: 0.0009, train_loss: 0.6967651\n",
            "[2021-02-10 07:28:53,699][INFO]: val - epoch: 6, val_loss: 0.7927176, val_f1facies: 0.6568512\n",
            "[2021-02-10 07:30:16,491][INFO]: train - epoch: 7, lr: 0.0009, train_loss: 0.696815\n",
            "[2021-02-10 07:30:17,030][INFO]: val - epoch: 7, val_loss: 0.7922332, val_f1facies: 0.6371708\n",
            "[2021-02-10 07:31:39,764][INFO]: train - epoch: 8, lr: 0.0009, train_loss: 0.6939351\n",
            "[2021-02-10 07:31:40,310][INFO]: val - epoch: 8, val_loss: 0.7798055, val_f1facies: 0.7234108\n",
            "[2021-02-10 07:31:40,416][INFO]: Model saved to 'panet_r1/model-008-0.723411.pth'\n",
            "[2021-02-10 07:33:03,074][INFO]: train - epoch: 9, lr: 0.0009, train_loss: 0.6935164\n",
            "[2021-02-10 07:33:03,624][INFO]: val - epoch: 9, val_loss: 0.7761014, val_f1facies: 0.6933556\n",
            "[2021-02-10 07:34:26,408][INFO]: train - epoch: 10, lr: 0.0009, train_loss: 0.6915622\n",
            "[2021-02-10 07:34:26,958][INFO]: val - epoch: 10, val_loss: 0.7853047, val_f1facies: 0.6038233\n",
            "[2021-02-10 07:35:49,803][INFO]: train - epoch: 11, lr: 0.0009, train_loss: 0.6892919\n",
            "[2021-02-10 07:35:50,340][INFO]: val - epoch: 11, val_loss: 0.7778014, val_f1facies: 0.7252837\n",
            "[2021-02-10 07:35:50,449][INFO]: Model saved to 'panet_r1/model-011-0.725284.pth'\n",
            "[2021-02-10 07:37:13,143][INFO]: train - epoch: 12, lr: 0.0009, train_loss: 0.6891602\n",
            "[2021-02-10 07:37:13,688][INFO]: val - epoch: 12, val_loss: 0.7624671, val_f1facies: 0.7763355\n",
            "[2021-02-10 07:37:13,801][INFO]: Model saved to 'panet_r1/model-012-0.776335.pth'\n",
            "[2021-02-10 07:38:36,747][INFO]: train - epoch: 13, lr: 0.0009, train_loss: 0.688061\n",
            "[2021-02-10 07:38:37,287][INFO]: val - epoch: 13, val_loss: 0.7781337, val_f1facies: 0.765064\n",
            "[2021-02-10 07:39:59,854][INFO]: train - epoch: 14, lr: 0.0009, train_loss: 0.6922489\n",
            "[2021-02-10 07:40:00,407][INFO]: val - epoch: 14, val_loss: 0.8095437, val_f1facies: 0.6794449\n",
            "[2021-02-10 07:41:23,602][INFO]: train - epoch: 15, lr: 0.0009, train_loss: 0.6899905\n",
            "[2021-02-10 07:41:24,149][INFO]: val - epoch: 15, val_loss: 0.7975246, val_f1facies: 0.658319\n",
            "[2021-02-10 07:42:46,838][INFO]: train - epoch: 16, lr: 0.0009, train_loss: 0.6855616\n",
            "[2021-02-10 07:42:47,384][INFO]: val - epoch: 16, val_loss: 0.7643789, val_f1facies: 0.7210034\n",
            "[2021-02-10 07:44:09,969][INFO]: train - epoch: 17, lr: 0.0009, train_loss: 0.6866899\n",
            "[2021-02-10 07:44:10,505][INFO]: val - epoch: 17, val_loss: 0.7497386, val_f1facies: 0.6861861\n",
            "[2021-02-10 07:45:33,222][INFO]: train - epoch: 18, lr: 0.0009, train_loss: 0.6853097\n",
            "[2021-02-10 07:45:33,767][INFO]: val - epoch: 18, val_loss: 0.7762946, val_f1facies: 0.6904357\n",
            "[2021-02-10 07:46:56,646][INFO]: train - epoch: 19, lr: 0.0009, train_loss: 0.6859568\n",
            "[2021-02-10 07:46:57,202][INFO]: val - epoch: 19, val_loss: 0.7672836, val_f1facies: 0.6704617\n",
            "[2021-02-10 07:48:20,113][INFO]: train - epoch: 20, lr: 0.0009, train_loss: 0.6856634\n",
            "[2021-02-10 07:48:20,659][INFO]: val - epoch: 20, val_loss: 0.7709833, val_f1facies: 0.7358364\n",
            "[2021-02-10 07:49:43,402][INFO]: train - epoch: 21, lr: 0.0009, train_loss: 0.6843725\n",
            "[2021-02-10 07:49:43,943][INFO]: val - epoch: 21, val_loss: 0.7681563, val_f1facies: 0.7062143\n",
            "[2021-02-10 07:51:06,533][INFO]: train - epoch: 22, lr: 0.0009, train_loss: 0.6855723\n",
            "[2021-02-10 07:51:07,067][INFO]: val - epoch: 22, val_loss: 0.7616504, val_f1facies: 0.704799\n",
            "[2021-02-10 07:52:29,949][INFO]: train - epoch: 23, lr: 0.0009, train_loss: 0.6824905\n",
            "[2021-02-10 07:52:30,514][INFO]: val - epoch: 23, val_loss: 0.7804642, val_f1facies: 0.6769544\n",
            "[2021-02-10 07:53:53,102][INFO]: train - epoch: 24, lr: 0.0009, train_loss: 0.6845094\n",
            "[2021-02-10 07:53:53,664][INFO]: val - epoch: 24, val_loss: 0.7535434, val_f1facies: 0.7136259\n",
            "[2021-02-10 07:55:16,403][INFO]: train - epoch: 25, lr: 0.0009, train_loss: 0.6849419\n",
            "[2021-02-10 07:55:16,962][INFO]: val - epoch: 25, val_loss: 0.7631021, val_f1facies: 0.7358437\n",
            "[2021-02-10 07:56:39,575][INFO]: train - epoch: 26, lr: 0.0009, train_loss: 0.6833037\n",
            "[2021-02-10 07:56:40,132][INFO]: val - epoch: 26, val_loss: 0.8043087, val_f1facies: 0.6298111\n",
            "[2021-02-10 07:58:02,750][INFO]: train - epoch: 27, lr: 0.0009, train_loss: 0.6830791\n",
            "[2021-02-10 07:58:03,287][INFO]: val - epoch: 27, val_loss: 0.7951567, val_f1facies: 0.6494843\n",
            "[2021-02-10 07:59:25,777][INFO]: train - epoch: 28, lr: 0.0009, train_loss: 0.6910153\n",
            "[2021-02-10 07:59:26,323][INFO]: val - epoch: 28, val_loss: 0.7736395, val_f1facies: 0.6872833\n",
            "[2021-02-10 08:00:48,806][INFO]: train - epoch: 29, lr: 0.0009, train_loss: 0.6831183\n",
            "[2021-02-10 08:00:49,348][INFO]: val - epoch: 29, val_loss: 0.7678652, val_f1facies: 0.67726\n",
            "[2021-02-10 08:02:11,859][INFO]: train - epoch: 30, lr: 0.0009, train_loss: 0.6834043\n",
            "[2021-02-10 08:02:12,410][INFO]: val - epoch: 30, val_loss: 0.7566345, val_f1facies: 0.7517333\n",
            "[2021-02-10 08:03:34,785][INFO]: train - epoch: 31, lr: 0.0009, train_loss: 0.6823209\n",
            "[2021-02-10 08:03:35,330][INFO]: val - epoch: 31, val_loss: 0.7505258, val_f1facies: 0.7619394\n",
            "[2021-02-10 08:04:57,924][INFO]: train - epoch: 32, lr: 0.0009, train_loss: 0.6818941\n",
            "[2021-02-10 08:04:58,494][INFO]: val - epoch: 32, val_loss: 0.7426599, val_f1facies: 0.7736139\n",
            "[2021-02-10 08:06:20,897][INFO]: train - epoch: 33, lr: 0.0009, train_loss: 0.6810054\n",
            "[2021-02-10 08:06:21,445][INFO]: val - epoch: 33, val_loss: 0.753482, val_f1facies: 0.7461341\n",
            "[2021-02-10 08:07:43,869][INFO]: train - epoch: 34, lr: 0.0009, train_loss: 0.6801991\n",
            "[2021-02-10 08:07:44,411][INFO]: val - epoch: 34, val_loss: 0.7453276, val_f1facies: 0.7492198\n",
            "[2021-02-10 08:09:06,824][INFO]: train - epoch: 35, lr: 0.0009, train_loss: 0.6829281\n",
            "[2021-02-10 08:09:07,358][INFO]: val - epoch: 35, val_loss: 0.7591715, val_f1facies: 0.6425028\n",
            "[2021-02-10 08:10:29,890][INFO]: train - epoch: 36, lr: 0.0009, train_loss: 0.679949\n",
            "[2021-02-10 08:10:30,437][INFO]: val - epoch: 36, val_loss: 0.7690666, val_f1facies: 0.6949281\n",
            "[2021-02-10 08:11:53,057][INFO]: train - epoch: 37, lr: 0.0009, train_loss: 0.6874928\n",
            "[2021-02-10 08:11:53,600][INFO]: val - epoch: 37, val_loss: 0.8106516, val_f1facies: 0.6560172\n",
            "[2021-02-10 08:13:16,069][INFO]: train - epoch: 38, lr: 0.0009, train_loss: 0.6849111\n",
            "[2021-02-10 08:13:16,618][INFO]: val - epoch: 38, val_loss: 0.7678372, val_f1facies: 0.673898\n",
            "[2021-02-10 08:14:38,869][INFO]: train - epoch: 39, lr: 0.0009, train_loss: 0.681997\n",
            "[2021-02-10 08:14:39,404][INFO]: val - epoch: 39, val_loss: 0.7563523, val_f1facies: 0.74257\n",
            "[2021-02-10 08:16:01,536][INFO]: train - epoch: 40, lr: 0.0009, train_loss: 0.6796867\n",
            "[2021-02-10 08:16:02,091][INFO]: val - epoch: 40, val_loss: 0.7655182, val_f1facies: 0.7277573\n",
            "[2021-02-10 08:17:24,569][INFO]: train - epoch: 41, lr: 0.0009, train_loss: 0.6818594\n",
            "[2021-02-10 08:17:25,110][INFO]: val - epoch: 41, val_loss: 0.749142, val_f1facies: 0.7482342\n",
            "[2021-02-10 08:18:47,384][INFO]: train - epoch: 42, lr: 0.0009, train_loss: 0.6800727\n",
            "[2021-02-10 08:18:47,932][INFO]: val - epoch: 42, val_loss: 0.7690986, val_f1facies: 0.6950915\n",
            "[2021-02-10 08:20:10,470][INFO]: train - epoch: 43, lr: 0.0009, train_loss: 0.6811229\n",
            "[2021-02-10 08:20:11,021][INFO]: val - epoch: 43, val_loss: 0.7551736, val_f1facies: 0.7411316\n",
            "[2021-02-10 08:21:33,075][INFO]: train - epoch: 44, lr: 0.0009, train_loss: 0.6830636\n",
            "[2021-02-10 08:21:33,616][INFO]: val - epoch: 44, val_loss: 0.7573397, val_f1facies: 0.7137187\n",
            "[2021-02-10 08:22:56,161][INFO]: train - epoch: 45, lr: 0.0009, train_loss: 0.6800073\n",
            "[2021-02-10 08:22:56,708][INFO]: val - epoch: 45, val_loss: 0.7788183, val_f1facies: 0.6341784\n",
            "[2021-02-10 08:24:18,912][INFO]: train - epoch: 46, lr: 0.0009, train_loss: 0.6836171\n",
            "[2021-02-10 08:24:19,467][INFO]: val - epoch: 46, val_loss: 0.7705681, val_f1facies: 0.7037367\n",
            "[2021-02-10 08:25:41,865][INFO]: train - epoch: 47, lr: 0.0009, train_loss: 0.6808224\n",
            "[2021-02-10 08:25:42,399][INFO]: val - epoch: 47, val_loss: 0.7674077, val_f1facies: 0.6944438\n",
            "[2021-02-10 08:27:04,759][INFO]: train - epoch: 48, lr: 0.0009, train_loss: 0.6796285\n",
            "[2021-02-10 08:27:05,296][INFO]: val - epoch: 48, val_loss: 0.7586334, val_f1facies: 0.7360179\n",
            "[2021-02-10 08:28:27,590][INFO]: train - epoch: 49, lr: 0.0009, train_loss: 0.6813718\n",
            "[2021-02-10 08:28:28,125][INFO]: val - epoch: 49, val_loss: 0.7597331, val_f1facies: 0.7455895\n",
            "[2021-02-10 08:29:50,158][INFO]: train - epoch: 50, lr: 0.0009, train_loss: 0.678388\n",
            "[2021-02-10 08:29:50,705][INFO]: val - epoch: 50, val_loss: 0.7554988, val_f1facies: 0.703352\n",
            "[2021-02-10 08:31:13,336][INFO]: train - epoch: 51, lr: 0.0009, train_loss: 0.6791691\n",
            "[2021-02-10 08:31:13,871][INFO]: val - epoch: 51, val_loss: 0.7440738, val_f1facies: 0.7273368\n",
            "[2021-02-10 08:32:35,991][INFO]: train - epoch: 52, lr: 0.0009, train_loss: 0.6790383\n",
            "[2021-02-10 08:32:36,535][INFO]: val - epoch: 52, val_loss: 0.744563, val_f1facies: 0.7575248\n",
            "[2021-02-10 08:33:58,901][INFO]: train - epoch: 53, lr: 0.0009, train_loss: 0.6789019\n",
            "[2021-02-10 08:33:59,447][INFO]: val - epoch: 53, val_loss: 0.751291, val_f1facies: 0.7264873\n",
            "[2021-02-10 08:35:21,658][INFO]: train - epoch: 54, lr: 0.0009, train_loss: 0.6787744\n",
            "[2021-02-10 08:35:22,205][INFO]: val - epoch: 54, val_loss: 0.7744204, val_f1facies: 0.6892781\n",
            "[2021-02-10 08:36:44,541][INFO]: train - epoch: 55, lr: 0.0009, train_loss: 0.679457\n",
            "[2021-02-10 08:36:45,084][INFO]: val - epoch: 55, val_loss: 0.7526404, val_f1facies: 0.7440013\n",
            "[2021-02-10 08:38:07,488][INFO]: train - epoch: 56, lr: 0.0009, train_loss: 0.6790498\n",
            "[2021-02-10 08:38:08,034][INFO]: val - epoch: 56, val_loss: 0.7411223, val_f1facies: 0.7446856\n",
            "[2021-02-10 08:39:30,507][INFO]: train - epoch: 57, lr: 0.0009, train_loss: 0.6801033\n",
            "[2021-02-10 08:39:31,053][INFO]: val - epoch: 57, val_loss: 0.773918, val_f1facies: 0.647379\n",
            "[2021-02-10 08:40:53,164][INFO]: train - epoch: 58, lr: 0.0009, train_loss: 0.679412\n",
            "[2021-02-10 08:40:53,707][INFO]: val - epoch: 58, val_loss: 0.7578822, val_f1facies: 0.7770511\n",
            "[2021-02-10 08:40:53,820][INFO]: Model saved to 'panet_r1/model-058-0.777051.pth'\n",
            "[2021-02-10 08:42:16,179][INFO]: train - epoch: 59, lr: 0.0009, train_loss: 0.6785278\n",
            "[2021-02-10 08:42:16,727][INFO]: val - epoch: 59, val_loss: 0.7622505, val_f1facies: 0.7222898\n",
            "[2021-02-10 08:43:38,979][INFO]: train - epoch: 60, lr: 0.0009, train_loss: 0.6793811\n",
            "[2021-02-10 08:43:39,543][INFO]: val - epoch: 60, val_loss: 0.7705465, val_f1facies: 0.7129611\n",
            "[2021-02-10 08:45:02,361][INFO]: train - epoch: 61, lr: 0.0009, train_loss: 0.6782496\n",
            "[2021-02-10 08:45:02,897][INFO]: val - epoch: 61, val_loss: 0.7581028, val_f1facies: 0.6961615\n",
            "[2021-02-10 08:46:25,040][INFO]: train - epoch: 62, lr: 0.0009, train_loss: 0.679617\n",
            "[2021-02-10 08:46:25,587][INFO]: val - epoch: 62, val_loss: 0.7462064, val_f1facies: 0.73446\n",
            "[2021-02-10 08:47:47,785][INFO]: train - epoch: 63, lr: 0.0009, train_loss: 0.6771588\n",
            "[2021-02-10 08:47:48,336][INFO]: val - epoch: 63, val_loss: 0.75113, val_f1facies: 0.7229461\n",
            "[2021-02-10 08:49:10,413][INFO]: train - epoch: 64, lr: 0.0009, train_loss: 0.6783987\n",
            "[2021-02-10 08:49:10,959][INFO]: val - epoch: 64, val_loss: 0.7513387, val_f1facies: 0.7808933\n",
            "[2021-02-10 08:49:11,069][INFO]: Model saved to 'panet_r1/model-064-0.780893.pth'\n",
            "[2021-02-10 08:50:33,521][INFO]: train - epoch: 65, lr: 0.0009, train_loss: 0.6804401\n",
            "[2021-02-10 08:50:34,077][INFO]: val - epoch: 65, val_loss: 0.7604619, val_f1facies: 0.7549241\n",
            "[2021-02-10 08:51:56,437][INFO]: train - epoch: 66, lr: 0.0009, train_loss: 0.6787721\n",
            "[2021-02-10 08:51:56,984][INFO]: val - epoch: 66, val_loss: 0.7577608, val_f1facies: 0.7465204\n",
            "[2021-02-10 08:53:19,402][INFO]: train - epoch: 67, lr: 0.0009, train_loss: 0.6786269\n",
            "[2021-02-10 08:53:19,959][INFO]: val - epoch: 67, val_loss: 0.7522538, val_f1facies: 0.7697123\n",
            "[2021-02-10 08:54:42,231][INFO]: train - epoch: 68, lr: 0.0009, train_loss: 0.6784838\n",
            "[2021-02-10 08:54:42,780][INFO]: val - epoch: 68, val_loss: 0.7661109, val_f1facies: 0.7519044\n",
            "[2021-02-10 08:56:05,213][INFO]: train - epoch: 69, lr: 0.0009, train_loss: 0.6767778\n",
            "[2021-02-10 08:56:05,757][INFO]: val - epoch: 69, val_loss: 0.7595842, val_f1facies: 0.7752543\n",
            "[2021-02-10 08:57:27,934][INFO]: train - epoch: 70, lr: 0.0009, train_loss: 0.6773808\n",
            "[2021-02-10 08:57:28,482][INFO]: val - epoch: 70, val_loss: 0.7530248, val_f1facies: 0.7673134\n",
            "[2021-02-10 08:58:51,178][INFO]: train - epoch: 71, lr: 0.0009, train_loss: 0.6769902\n",
            "[2021-02-10 08:58:51,720][INFO]: val - epoch: 71, val_loss: 0.7505767, val_f1facies: 0.7705776\n",
            "[2021-02-10 09:00:14,070][INFO]: train - epoch: 72, lr: 0.0009, train_loss: 0.6786672\n",
            "[2021-02-10 09:00:14,613][INFO]: val - epoch: 72, val_loss: 0.748137, val_f1facies: 0.7262563\n",
            "[2021-02-10 09:01:37,034][INFO]: train - epoch: 73, lr: 0.0009, train_loss: 0.6783549\n",
            "[2021-02-10 09:01:37,586][INFO]: val - epoch: 73, val_loss: 0.7443465, val_f1facies: 0.7843164\n",
            "[2021-02-10 09:01:37,702][INFO]: Model saved to 'panet_r1/model-073-0.784316.pth'\n",
            "[2021-02-10 09:03:00,214][INFO]: train - epoch: 74, lr: 0.0009, train_loss: 0.6775016\n",
            "[2021-02-10 09:03:00,773][INFO]: val - epoch: 74, val_loss: 0.7516728, val_f1facies: 0.7457872\n",
            "[2021-02-10 09:04:22,868][INFO]: train - epoch: 75, lr: 0.0009, train_loss: 0.6788367\n",
            "[2021-02-10 09:04:23,401][INFO]: val - epoch: 75, val_loss: 0.7627316, val_f1facies: 0.7267585\n",
            "[2021-02-10 09:05:45,602][INFO]: train - epoch: 76, lr: 0.0009, train_loss: 0.6779519\n",
            "[2021-02-10 09:05:46,164][INFO]: val - epoch: 76, val_loss: 0.7380403, val_f1facies: 0.7739102\n",
            "[2021-02-10 09:07:08,402][INFO]: train - epoch: 77, lr: 0.0009, train_loss: 0.6768947\n",
            "[2021-02-10 09:07:08,945][INFO]: val - epoch: 77, val_loss: 0.7467335, val_f1facies: 0.7665786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re5n-CyoFDpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dcd750-ffda-4f59-84f8-02d22b8edb8b"
      },
      "source": [
        "#incase you got semi-banned because using gpu too long, here's my checkpoint\n",
        "!gdown \"https://drive.google.com/uc?id=1OTZFF9en1uSYkAZ7NCaFaL4cP-qXdPMP\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OTZFF9en1uSYkAZ7NCaFaL4cP-qXdPMP\n",
            "To: /content/model-097-0.799478.pth\n",
            "43.7MB [00:02, 21.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzKPNu7NHlQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cac643-6835-4c16-ee60-914b43b38d82"
      },
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1oLCwcBdfJ3SUdKpuq2Cgagrbf1tcRpFZ\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oLCwcBdfJ3SUdKpuq2Cgagrbf1tcRpFZ\n",
            "To: /content/data_test_2_procsed.npz\n",
            "986MB [00:07, 135MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6bJCtbtVzs_"
      },
      "source": [
        "test_dat2 = np.load('data_test_2_procsed.npz', allow_pickle=True, mmap_mode='r')['data']\n",
        "test_dat2 = test_dat2.transpose(1, 0, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKrseI6e0DZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b73cb8-a6db-421a-9905-032820956386"
      },
      "source": [
        "import cv2\n",
        "model = argus.load_model('model-097-0.799478.pth')\n",
        "\n",
        "pred=np.zeros([test_dat2.shape[1],test_dat2.shape[2],test_dat2.shape[0]],dtype=int)\n",
        "print('predicting...')\n",
        "for i in range(0,test_dat2.shape[0]):\n",
        "    for j in range(0,7):\n",
        "        if j==6:\n",
        "            tempcek=test_dat2[i,:,test_dat2.shape[2]-130:]\n",
        "        else: \n",
        "            tempcek=test_dat2[i,:,j*130:130+j*130]\n",
        "        temp=cv2.resize(tempcek, (128,1000), interpolation=cv2.INTER_NEAREST)\n",
        "        temp=temp[None,None,:,:]\n",
        "        score = model.predict(torch.from_numpy(temp).float())\n",
        "        temppred = score.max(1)[1].cpu().numpy()[:, :, :]+1\n",
        "        temp2 = cv2.resize(temppred[0,:,:], (130,1006), interpolation=cv2.INTER_NEAREST)\n",
        "        \n",
        "        if j==6:\n",
        "            pred[:,test_dat2.shape[2]-130:,i]=temp2\n",
        "        else: \n",
        "            pred[:,j*130:130+j*130,i]=temp2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicting...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "5mrmVbBWH_Jx",
        "outputId": "eb290608-7471-44ee-8a8b-0a7e8963647b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "plt.imshow(pred[:,:,1],cmap='Pastel1', interpolation='none')\n",
        "plt.title('Result test-2 slice#1')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}